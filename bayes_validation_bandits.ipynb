{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bxPeVnpksepA",
    "outputId": "f82b5e9a-b88f-48d4-a852-411c20658e3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: False\n"
     ]
    }
   ],
   "source": [
    "from core import *\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "from bandits import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "appsi0oRMy5K",
    "outputId": "b628b0c3-72c2-4ef7-a6d2-42b6213a958a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "PI: 0.25\n",
      "Sigma1: 1.0\n",
      "Sigma2: 0.0024787521766663585\n",
      "Step 99. Regret 635.0\n",
      "Step 199. Regret 1385.0\n",
      "Step 299. Regret 1900.0\n",
      "Step 399. Regret 2365.0\n",
      "Step 499. Regret 2855.0\n",
      "Step 599. Regret 3470.0\n",
      "Step 699. Regret 4150.0\n",
      "Step 799. Regret 4585.0\n",
      "Step 899. Regret 5165.0\n",
      "Step 999. Regret 5825.0\n",
      "Step 1099. Regret 6325.0\n",
      "Step 1199. Regret 7065.0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# hypers that do not need to be tuned\n",
    "N_Steps = 6000 # in actual training, we use 6000\n",
    "\n",
    "# Load the UCI Mushroom Dataset: 8124 datapoints, each with 22 categorical\n",
    "# features and one label - edible/poisonous. The features are transformed to a\n",
    "# one-hot encoding. \n",
    "# The missing values (marked with ?) are treated as a different class for now.\n",
    "\n",
    "mushroom_dataset = pd.read_csv('mushrooms.csv')\n",
    "train_labels = mushroom_dataset['class']\n",
    "train_labels = train_labels.replace(['p', 'e'],\n",
    "                                    [POISONOUS_CONSTANT, EDIBLE_CONSTANT])\n",
    "train_features = pd.get_dummies(mushroom_dataset.drop(['class'], axis=1))\n",
    "\n",
    "train_features = torch.tensor(train_features.values, dtype=torch.float)\n",
    "train_labels = torch.tensor(train_labels.values)\n",
    "\n",
    "trainset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "# TODO: cannot specify the hyper for priors outside the network\n",
    "\n",
    "LearningRate_candidates = [1e-4, 1e-3]\n",
    "Epsilon_candidates = [0.1, 0.01, 0.001]\n",
    "mixture_PI_candidates = [0.25, 0.5, 0.75]\n",
    "mixture_sigma1_candidates = [math.exp(-0), math.exp(-1), math.exp(-2)]\n",
    "mixture_sigma2_candidates = [math.exp(-6), math.exp(-7), math.exp(-8)]\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epsilon = 0.001\n",
    "\n",
    "hyper_val_error_dict = {}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # could may have more\n",
    "    hyper_list = itertools.product(mixture_PI_candidates,\n",
    "                                   mixture_sigma1_candidates,\n",
    "                                   mixture_sigma2_candidates)\n",
    "    \n",
    "    for pi, sigma1, sigma2  in hyper_list:\n",
    "      \n",
    "      print(\"*\"*50)\n",
    "      \n",
    "      print('PI: {}'.format(pi))\n",
    "      print('Sigma1: {}'.format(sigma1))\n",
    "      print('Sigma2: {}'.format(sigma2))\n",
    "      \n",
    "      # Initialize network\n",
    "      optimizer_constructor = torch.optim.Adam\n",
    "      optimizer_params = {'lr': learning_rate, 'eps': epsilon}\n",
    "      prior_params = {'pi': pi, 'sigma1': sigma1, 'sigma2': sigma2}\n",
    "      \n",
    "      bnn_agent = BNNAgent(optimizer_constructor=optimizer_constructor,\n",
    "                           optim_params=optimizer_params,\n",
    "                           prior_params=prior_params)\n",
    "      bnn_env = Environment(bnn_agent, trainloader)\n",
    "\n",
    "      loss = []\n",
    "      regret = []\n",
    "        \n",
    "\n",
    "      for i_step in range(N_Steps):\n",
    "\n",
    "          # Training\n",
    "          loss.append(bnn_env.play_round())\n",
    "          regret.append(bnn_env.cumulative_regret)\n",
    "          \n",
    "          if (i_step + 1) % 100 == 0:\n",
    "            print('Step {}. Regret {}'.format(i_step, bnn_env.cumulative_regret))\n",
    "\n",
    "      plt.plot(np.array(loss))\n",
    "      plt.ylabel('Loss')\n",
    "      plt.show()\n",
    "    \n",
    "      plt.plot(np.array(regret))\n",
    "      plt.ylabel('Cumulative Regret')\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bayes_validation_bandits.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
