{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "density plot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wGX6g6bijpvo",
        "colab_type": "code",
        "outputId": "c810482b-ce12-42ae-940a-596fcc4106f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.utils.data\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from torch import distributions as dist\n",
        "from enum import Enum\n",
        "\n",
        "# boolean variable that indicates whether or not we have gpu...\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(\"Use GPU: {}\".format(use_cuda))\n",
        "\n",
        "# Default gaussian mixture parameters\n",
        "PI = 0.5\n",
        "\n",
        "SIGMA_1 = torch.tensor([math.exp(-0)])\n",
        "SIGMA_2 = torch.tensor([math.exp(-6)])\n",
        "\n",
        "# place tensor in GPU if use_cuda\n",
        "if use_cuda:\n",
        "  SIGMA_1 = SIGMA_1.cuda()\n",
        "  SIGMA_2 = SIGMA_2.cuda()\n",
        "\n",
        "# Default gaussian parameters\n",
        "MU_PRIOR = 0\n",
        "SIGMA_PRIOR = torch.tensor([math.exp(-0)])\n",
        "\n",
        "# place tensor in GPU if use_cuda\n",
        "if use_cuda:\n",
        "    SIGMA_PRIOR = SIGMA_PRIOR.cuda()\n",
        "\n",
        "# Initial weight hyperparameters\n",
        "MU_WEIGHTS = (-0.03, 0.03)\n",
        "RHO_WEIGHTS = (-8, -7)\n",
        "MU_BIAS = (-0.03, 0.03)\n",
        "RHO_BIAS = (-8, -7)\n",
        "\n",
        "# Loss variance\n",
        "SIGMA = torch.tensor([math.exp(-2)])\n",
        "\n",
        "# place tensor in GPU if use_cuda\n",
        "if use_cuda:\n",
        "    SIGMA = SIGMA.cuda()\n",
        "\n",
        "class PriorType(Enum):\n",
        "  MIXTURE = 1\n",
        "  GAUSSIAN = 2\n",
        "\n",
        "class ActivationType(Enum):\n",
        "  NONE = 0\n",
        "  RELU = 1\n",
        "  SOFTMAX = 2\n",
        "  TANH = 3\n",
        "  SIGMOID = 4\n",
        "\n",
        "class TaskType(Enum):\n",
        "  REGRESSION = 1\n",
        "  CLASSIFICATION = 2\n",
        "\n",
        "class GaussianMixture(object):\n",
        "\n",
        "  def __init__(self, pi, sigma1, sigma2):\n",
        "    self.pi = pi\n",
        "    self.sigma1 = sigma1\n",
        "    self.sigma2 = sigma2\n",
        "    if use_cuda:\n",
        "      self.sigma1 = self.sigma1.cuda()\n",
        "      self.sigma2 = self.sigma2.cuda()\n",
        "    print(self.sigma1)\n",
        "    print(self.sigma2)\n",
        "\n",
        "  # arguments of dist.Normal() should be tensors rather than scalars\n",
        "  def log_prob(self, weights):\n",
        "    new_weights = weights.view(-1)\n",
        "    normal_density1 = dist.Normal(0,self.sigma1).log_prob(new_weights)\n",
        "    exp_normal_density1 = torch.exp(normal_density1)\n",
        "    exp_normal_density2 = torch.exp(\n",
        "        dist.Normal(0.0, self.sigma2).log_prob(new_weights))\n",
        "    nonzero = exp_normal_density2.nonzero()\n",
        "    zero = (exp_normal_density2==0).nonzero()\n",
        "    sum_log_prob = torch.sum(torch.log(self.pi * torch.take(exp_normal_density1,nonzero) \\\n",
        "                  + (1-self.pi)*torch.take(exp_normal_density2,nonzero))) \\\n",
        "                  + torch.sum(torch.take(normal_density1, zero)+np.log(self.pi))\n",
        "    return sum_log_prob\n",
        "  '''def log_prob(self, weights):\n",
        "    normal_density1 = torch.exp(\n",
        "        dist.Normal(0.0, self.sigma1).log_prob(weights))\n",
        "    normal_density2 = torch.exp(\n",
        "        dist.Normal(0.0, self.sigma2).log_prob(weights))\n",
        "    sum_log_prob = torch.sum(torch.log(self.pi * normal_density1 + (1-self.pi)*normal_density2))\n",
        "    return sum_log_prob'''\n",
        "\n",
        "class BayesianLayer(nn.Module):\n",
        "\n",
        "  def __init__(self,\n",
        "               input_size,\n",
        "               output_size,\n",
        "               prior_type=PriorType.MIXTURE,\n",
        "               prior_params={'pi' : PI, 'sigma1' : SIGMA_1, 'sigma2' : SIGMA_2},\n",
        "               activation_type=ActivationType.NONE,\n",
        "               initial_mu_weights=MU_WEIGHTS,\n",
        "               initial_mu_bias=MU_BIAS,\n",
        "               initial_rho_weights=RHO_WEIGHTS,\n",
        "               initial_rho_bias=RHO_BIAS\n",
        "              ):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.output_size = output_size\n",
        "    self.activation_type = activation_type\n",
        "\n",
        "    # create torch variables\n",
        "    if not use_cuda:\n",
        "        self.mu_weights = nn.Parameter(torch.Tensor(output_size, input_size))\n",
        "        self.rho_weights = nn.Parameter(torch.Tensor(output_size, input_size))\n",
        "        self.mu_bias = nn.Parameter(torch.Tensor(output_size))\n",
        "        self.rho_bias = nn.Parameter(torch.Tensor(output_size))\n",
        "        self.normal_dist = dist.Normal(torch.Tensor([0]), torch.Tensor([1]))\n",
        "    else:\n",
        "        self.mu_weights = nn.Parameter(torch.Tensor(output_size, input_size).cuda())\n",
        "        self.rho_weights = nn.Parameter(torch.Tensor(output_size, input_size).cuda())\n",
        "        self.mu_bias = nn.Parameter(torch.Tensor(output_size).cuda())\n",
        "        self.rho_bias = nn.Parameter(torch.Tensor(output_size).cuda())\n",
        "        self.normal_dist = dist.Normal(torch.Tensor([0]).cuda(), torch.Tensor([1]).cuda())\n",
        "\n",
        "    # initialize variables\n",
        "    self.mu_weights.data.uniform_(*initial_mu_weights)\n",
        "    self.rho_weights.data.uniform_(*initial_rho_weights)\n",
        "    self.mu_bias.data.uniform_(*initial_mu_bias)\n",
        "    self.rho_bias.data.uniform_(*initial_rho_bias)\n",
        "\n",
        "    if prior_type == PriorType.MIXTURE:\n",
        "      self.prior_weights = GaussianMixture(\n",
        "          prior_params['pi'], prior_params['sigma1'], prior_params['sigma2'])\n",
        "      self.prior_bias = GaussianMixture(\n",
        "          prior_params['pi'], prior_params['sigma1'], prior_params['sigma2'])\n",
        "    else:\n",
        "      self.prior_weights = dist.Normal(prior_params['mean'],\n",
        "                                       prior_params['sigma'])\n",
        "      self.prior_bias = dist.Normal(prior_params['mean'],\n",
        "                                    prior_params['sigma'])\n",
        "    self.log_prior = 0\n",
        "    self.log_posterior = 0\n",
        "\n",
        "  def _compute_gaussian_sample(self, mu, rho):\n",
        "    epsilon = self.normal_dist.sample(rho.size()).squeeze(-1)\n",
        "    return mu + torch.log(1 + torch.exp(rho)) * epsilon\n",
        "\n",
        "  def forward(self, input_data, sample=False, debug=False):\n",
        "    if self.training or sample:\n",
        "      weights = self._compute_gaussian_sample(self.mu_weights, self.rho_weights)\n",
        "      bias = self._compute_gaussian_sample(self.mu_bias, self.rho_bias)\n",
        "      if debug is True:\n",
        "        pass\n",
        "        # print(\"sampled weights:\")\n",
        "        # print(weights)\n",
        "      self.log_prior = (self.prior_weights.log_prob(weights).sum() +\n",
        "                        self.prior_bias.log_prob(bias).sum() )\n",
        "      sigma_weights = torch.log(1 + torch.exp(self.rho_weights))\n",
        "      sigma_bias = torch.log(1 + torch.exp(self.rho_bias))\n",
        "      self.log_posterior = (\n",
        "          dist.Normal(\n",
        "              self.mu_weights, sigma_weights).log_prob(weights).sum() +\n",
        "          dist.Normal(self.mu_bias, sigma_bias).log_prob(bias).sum()\n",
        "      )\n",
        "\n",
        "      if torch.isnan(self.log_posterior):\n",
        "        print('Weights log prob: ')\n",
        "        print( dist.Normal(\n",
        "              self.mu_weights, sigma_weights).log_prob(weights).sum())\n",
        "        print('Bias log prob: ' )\n",
        "        print(dist.Normal(self.mu_bias, sigma_bias).log_prob(bias).sum())\n",
        "    else:\n",
        "      weights = self.mu_weights\n",
        "      bias = self.mu_bias\n",
        "\n",
        "    linear_output = nn.functional.linear(input_data, weights, bias)\n",
        "    output = linear_output\n",
        "    if self.activation_type == ActivationType.RELU:\n",
        "      output = torch.relu(linear_output)\n",
        "    elif self.activation_type == ActivationType.SOFTMAX:\n",
        "      output = torch.log_softmax(linear_output, dim=1)\n",
        "    elif self.activation_type == ActivationType.SIGMOID:\n",
        "      output = torch.sigmoid(linear_output)\n",
        "    elif self.activation_type == ActivationType.TANH:\n",
        "      output = torch.tanh(linear_output)\n",
        "    elif self.activation_type == ActivationType.NONE:\n",
        "      output = linear_output\n",
        "    else:\n",
        "      raise ValueError('activation_type {} not support'.format(self.activation_type))\n",
        "    return output\n",
        "\n",
        "  def extra_repr(self):\n",
        "    return 'Bayesian Layer, in_size:{}, out_size:{}, activation_type:{}'.format(\n",
        "      self.input_size, self.output_size, self.activation_type.name\n",
        "    )\n",
        "\n",
        "class BayesianNN(nn.Module):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      nn_input_size,\n",
        "      layer_config=[100, 100, 10],           # list of layer output sizes\n",
        "      activation_config=[ActivationType.RELU, ActivationType.RELU, ActivationType.NONE],\n",
        "      prior_type=PriorType.MIXTURE,\n",
        "      prior_params={'pi' : PI, 'sigma1' : SIGMA_1, 'sigma2' : SIGMA_2},\n",
        "      task_type=TaskType.REGRESSION,         # determines the likelihood form\n",
        "      initial_mu_weights=MU_WEIGHTS,\n",
        "      initial_mu_bias=MU_BIAS,\n",
        "      initial_rho_weights=RHO_WEIGHTS,\n",
        "      initial_rho_bias=RHO_BIAS\n",
        "  ):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layers = nn.ModuleList([]) # ensures that all params are registered\n",
        "    self.input_size = nn_input_size\n",
        "    for i, output_size in enumerate(layer_config):\n",
        "      if i == 0:\n",
        "        input_size = self.input_size\n",
        "      else:\n",
        "        input_size = layer_config[i-1]\n",
        "\n",
        "      bayesian_layer = BayesianLayer(input_size, output_size,\n",
        "                                     activation_type = activation_config[i],\n",
        "                                     prior_type=prior_type,\n",
        "                                     prior_params=prior_params,\n",
        "                                     initial_mu_weights=initial_mu_weights,\n",
        "                                     initial_mu_bias=initial_mu_bias,\n",
        "                                     initial_rho_weights=initial_rho_weights,\n",
        "                                     initial_rho_bias=initial_rho_bias)\n",
        "      self.layers.append(bayesian_layer)\n",
        "    self.output_size = self.layers[-1].output_size\n",
        "    self.task_type = task_type\n",
        "\n",
        "  def forward(self, input_data, sample=True, debug=False):\n",
        "    current_data = input_data\n",
        "    for layer in self.layers:\n",
        "      current_data = layer.forward(current_data, sample, debug=debug)\n",
        "    if sample is False:\n",
        "        print(\"not sampling.\")\n",
        "    return current_data\n",
        "\n",
        "  # sample a bunch of weights for the network\n",
        "  # make predictions using sampled weights\n",
        "  # output averaged predictions from different sampled weights\n",
        "  def predict_by_sampling(self, input_data, num_samples=1):\n",
        "    # reduce the use of memory\n",
        "    with torch.no_grad():\n",
        "        outputs = torch.empty(num_samples, input_data.size()[0], self.output_size)\n",
        "        for i in range(num_samples):\n",
        "            # print(\"*\"*20)\n",
        "            outputs[i] = self.forward(input_data, sample=True, debug=True)\n",
        "            # print(outputs[i][0])\n",
        "            # print(\"*\"*20)\n",
        "        stds = outputs.std(0)\n",
        "        # print(\"std in probability distributions:\", stds.mean(0))\n",
        "        outputs = outputs.mean(0)\n",
        "    return outputs\n",
        "\n",
        "  def log_prior(self):\n",
        "    log_prior = 0\n",
        "    for layer in self.layers:\n",
        "      log_prior += layer.log_prior\n",
        "    return log_prior\n",
        "\n",
        "  def log_posterior(self):\n",
        "    log_posterior = 0\n",
        "    for layer in self.layers:\n",
        "      log_posterior += layer.log_posterior\n",
        "    return log_posterior\n",
        "\n",
        "  def cost_function(self, inputs, targets, num_samples, ratio):\n",
        "    sum_log_posterior = 0\n",
        "    sum_log_prior = 0\n",
        "    sum_negative_log_likelihood = 0\n",
        "    for n in range(num_samples):\n",
        "      outputs = self(inputs, sample=True)\n",
        "      sum_log_posterior += self.log_posterior()\n",
        "      sum_log_prior += self.log_prior()\n",
        "      if self.task_type == TaskType.CLASSIFICATION:\n",
        "         # the outputs are from log_softmax activation function\n",
        "         log_probs = outputs[range(targets.size()[0]), targets]\n",
        "         # the negative sum of log probs is the negative log likelihood\n",
        "         # for this sampled neural network on this minibatch\n",
        "         negative_log_likelihood = -log_probs.sum()\n",
        "         # negative_log_likelihood = nn.functional.nll_loss(outputs, targets)\n",
        "      elif self.task_type == TaskType.REGRESSION:\n",
        "         negative_log_likelihood = - dist.Normal(\n",
        "             targets, SIGMA).log_prob(outputs).sum()\n",
        "      sum_negative_log_likelihood += negative_log_likelihood\n",
        "    kl_divergence = (sum_log_posterior / num_samples - sum_log_prior / num_samples) * ratio\n",
        "    negative_log_likelihood = sum_negative_log_likelihood / num_samples\n",
        "    loss =  kl_divergence + negative_log_likelihood\n",
        "    return loss, kl_divergence, negative_log_likelihood\n",
        "\n",
        "  def extra_repr(self):\n",
        "    repr = ''\n",
        "    for layer in self.layers:\n",
        "      repr += layer.extra_repr()\n",
        "      repr += '\\n'\n",
        "    return repr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use GPU: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G4Jfp_RFk8Nx",
        "colab_type": "code",
        "outputId": "d9d32496-007c-4000-c455-8f79eef037a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import torch.utils.data as Data\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import random\n",
        "import math\n",
        "import itertools\n",
        "import argparse\n",
        "import pickle\n",
        "import torch.nn.functional as f\n",
        "\n",
        "# check whether we are using GPU or not\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "N_Epochs =  600\n",
        "N_units = 1200\n",
        "LearningRate = 0.001\n",
        "BatchSize = 128\n",
        "optimizer_type = \"SGD\"\n",
        "preprocess = True\n",
        "N_Samples_Training = 2\n",
        "N_Samples_Testing = 100\n",
        "prior_type = \"scale_mixture\"\n",
        "mixture_sigma1 = torch.tensor([math.exp(-2)])\n",
        "mixture_sigma2 = torch.tensor([math.exp(-8)])\n",
        "mixture_pi = 0.75\n",
        "network_type = \"bayesian\"\n",
        "initial_mu_weights = [-0.08, 0.08]\n",
        "initial_rho_weights = [-2.5,-2.1]\n",
        "initial_mu_bias = [-0.08, 0.08]\n",
        "initial_rho_bias = [-2.5,-2.1]\n",
        "use_normalized = False\n",
        "\n",
        "\n",
        "import os.path\n",
        "dataset_path = os.path.join(os.path.dirname(\"\"), 'mnist_dataset')\n",
        "if not os.path.exists(dataset_path):\n",
        "    Download_MNIST = True\n",
        "else:\n",
        "    Download_MNIST = False\n",
        "\n",
        "if preprocess is True:\n",
        "    # transform = transforms.Compose([np.array, torch.FloatTensor, lambda x: torch.div(x,126.0)])\n",
        "    transform = transforms.Compose([torchvision.transforms.ToTensor(), lambda x: x*255/126])\n",
        "else:\n",
        "    transform = transforms.Compose([np.array, torch.FloatTensor])\n",
        "\n",
        "train_set = torchvision.datasets.MNIST(\n",
        "    root=dataset_path,\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=Download_MNIST\n",
        ")\n",
        "\n",
        "train_loader = Data.DataLoader(dataset=train_set, batch_size=BatchSize, shuffle=True)\n",
        "\n",
        "test_set = torchvision.datasets.MNIST(\n",
        "    root=dataset_path,\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=Download_MNIST\n",
        ")\n",
        "\n",
        "train_size = train_set.train_data.size()[0]\n",
        "N_Train_Batch = train_size / BatchSize\n",
        "test_size = test_set.test_data.size()[0]\n",
        "\n",
        "compute_accu = lambda pred, true, digits: round((pred == true).mean() * 100, digits)\n",
        "\n",
        "# build the network\n",
        "if network_type == \"standard\":\n",
        "    loss_fn = torch.nn.NLLLoss(reduction='sum')\n",
        "    if use_dropout:\n",
        "        dropout_rate = args.dropout_rate\n",
        "        net =  torch.nn.Sequential(\n",
        "            torch.nn.Linear(784, N_units),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout_rate),\n",
        "            torch.nn.Linear(N_units, N_units),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout_rate),\n",
        "            torch.nn.Linear(N_units, 10),\n",
        "            torch.nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "    else:\n",
        "        net = torch.nn.Sequential(\n",
        "            torch.nn.Linear(784, N_units),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(N_units, N_units),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(N_units, 10),\n",
        "            torch.nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "elif network_type == \"bayesian\":\n",
        "    if prior_type == 'scale_mixture':\n",
        "        prior_type = PriorType.MIXTURE\n",
        "        prior_params={'pi' : mixture_pi, 'sigma1' : mixture_sigma1, 'sigma2' : mixture_sigma2}\n",
        "    else:\n",
        "        prior_type = PriorType.GAUSSIAN\n",
        "        prior_params={'mean': gaussian_mean, 'sigma': gaussian_sigma}\n",
        "    net = BayesianNN(\n",
        "        nn_input_size=784,\n",
        "        layer_config=[N_units, N_units, 10],\n",
        "        activation_config=[ActivationType.RELU, ActivationType.RELU, ActivationType.SOFTMAX],\n",
        "        prior_type=prior_type,\n",
        "        prior_params=prior_params,\n",
        "        task_type=TaskType.CLASSIFICATION,\n",
        "        initial_mu_weights=initial_mu_weights,\n",
        "        initial_rho_weights=initial_rho_weights,\n",
        "        initial_mu_bias=initial_mu_bias,\n",
        "        initial_rho_bias=initial_rho_bias\n",
        "    )\n",
        "    print(\"initial mu weights:\", initial_mu_weights)\n",
        "    print(\"initial rho weights:\", initial_rho_weights)\n",
        "    print(\"initial mu bias:\", initial_mu_bias)\n",
        "    print(\"initial rho bias\", initial_rho_bias)\n",
        "else:\n",
        "    raise ValueError\n",
        "\n",
        "if use_cuda:\n",
        "    net = net.cuda()\n",
        "\n",
        "print(net)\n",
        "\n",
        "# build the optimizer\n",
        "if optimizer_type == \"SGD\":\n",
        "    optim = torch.optim.SGD(net.parameters(), lr=LearningRate)\n",
        "elif optimizer_type == \"Adam\":\n",
        "    optim = torch.optim.Adam(net.parameters(), lr=LearningRate)\n",
        "else:\n",
        "    raise ValueError\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=lr_scheduler_step_size, gamma=lr_scheduler_gamma)\n",
        "# the main training loop\n",
        "train_accu_lst = []\n",
        "test_accu_lst = []\n",
        "\n",
        "test_X = Variable(test_set.test_data.view(test_size, -1).type(torch.FloatTensor))\n",
        "test_Y = Variable(test_set.test_labels.view(test_size, -1))\n",
        "\n",
        "if use_cuda:\n",
        "    test_X, test_Y = test_X.cuda(), test_Y.cuda()\n",
        "\n",
        "train_X = Variable(train_set.train_data.view(train_size, -1).type(torch.FloatTensor))\n",
        "train_Y = Variable(train_set.train_labels.view(train_size, -1))\n",
        "\n",
        "# if use_cuda:\n",
        "#     train_X, train_Y = train_X.cuda(), train_Y.cuda()\n",
        "# import time\n",
        "# normalized_factor = 1/N_Train_Batch\n",
        "# for i_ep in range(N_Epochs):\n",
        "#     #scheduler.step()\n",
        "#     # Training\n",
        "#     net.train()\n",
        "#     if use_normalized:\n",
        "#         normalized_factor = 1\n",
        "#     total_loss = 0\n",
        "#     total_kl = 0\n",
        "#     start = time.time()\n",
        "#     for X, Y in train_loader:\n",
        "#         batch_X = Variable(X.view(X.size()[0], -1))\n",
        "#         batch_Y = Variable(Y.view(X.size()[0]))\n",
        "\n",
        "#         if use_normalized:\n",
        "#             normalized_factor /= 2\n",
        "#         if use_cuda:\n",
        "#             batch_X, batch_Y = batch_X.cuda(), batch_Y.cuda()\n",
        "\n",
        "#         # compute loss\n",
        "#         if network_type == 'standard':\n",
        "#             y_pred = net(batch_X)\n",
        "#             loss = loss_fn(y_pred, batch_Y)\n",
        "#         elif network_type == 'bayesian':\n",
        "#             loss, kl , _ = net.cost_function(batch_X, batch_Y, num_samples=N_Samples_Training, ratio = normalized_factor)\n",
        "#             total_loss += loss.item()\n",
        "#             total_kl += kl.item()\n",
        "#             # detect nan\n",
        "#             if torch.isnan(loss):\n",
        "#                 print(\"Loss NAN.\")\n",
        "#                 for p in net.parameters():\n",
        "#                     print(p)\n",
        "#                 raise ValueError\n",
        "#         else:\n",
        "#             raise ValueError\n",
        "\n",
        "#         # do backpropagation\n",
        "#         optim.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optim.step()\n",
        "#     end = time.time()\n",
        "#     print(end-start)\n",
        "#     # Evaluate on training set\n",
        "#     if network_type == 'standard':\n",
        "#         net.eval()\n",
        "#     # do not use evaluation mode for bayesian networks because we do sampling during testing\n",
        "#     if network_type == 'bayesian':\n",
        "#         print(total_loss, total_kl)\n",
        "\n",
        "#     # test on training set\n",
        "\n",
        "#     if network_type == 'standard':\n",
        "#         pred_class = net(train_X).cpu().data.numpy().argmax(axis=1)\n",
        "#     elif network_type == 'bayesian':\n",
        "#         pred_class = net.predict_by_sampling(train_X, num_samples=N_Samples_Testing).data.cpu().numpy().argmax(axis=1)\n",
        "#     else:\n",
        "#         raise ValueError\n",
        "\n",
        "#     true_class = train_Y.data.cpu().numpy().ravel()\n",
        "\n",
        "#     train_accu = compute_accu(pred_class, true_class, 2)\n",
        "#     print('Epoch', i_ep, '|  Training Accuracy:', train_accu, '%', '| Training Error: ', round(100-train_accu, 2), '%')\n",
        "\n",
        "#     train_accu_lst.append(train_accu)\n",
        "\n",
        "#     # test on testing set\n",
        "\n",
        "#     true_class = test_Y.data.cpu().numpy().ravel()\n",
        "\n",
        "#     if network_type == 'standard':\n",
        "#         pred_class = net(test_X).cpu().data.numpy().argmax(axis=1)\n",
        "#     elif network_type == 'bayesian':\n",
        "#         pred_class = net.predict_by_sampling(test_X, num_samples=N_Samples_Testing).data.cpu().numpy().argmax(axis=1)\n",
        "#         pred_class_without_sampling = net(test_X, sample=False).cpu().detach().numpy().argmax(axis=1)\n",
        "#         test_accu_without_sampling = compute_accu(pred_class_without_sampling, true_class, 2)\n",
        "#         print('Epoch', i_ep, '|  Test Accuracy without sampling:', test_accu_without_sampling, '%', '| Test Error: ', round(100-test_accu_without_sampling, 2), '%')\n",
        "#         pred_class_2 = net.predict_by_sampling(test_X, num_samples=2).data.cpu().numpy().argmax(axis=1)\n",
        "#         #pred_class_4 = net.predict_by_sampling(test_X, num_samples=4).data.cpu().numpy().argmax(axis=1)\n",
        "#         #pred_class_6 = net.predict_by_sampling(test_X, num_samples=6).data.cpu().numpy().argmax(axis=1)\n",
        "#         pred_class_20 = net.predict_by_sampling(test_X, num_samples=20).data.cpu().numpy().argmax(axis=1)\n",
        "#         #pred_class_100 = net.predict_by_sampling(test_X, num_samples=100).data.cpu().numpy().argmax(axis=1)\n",
        "#         #pred_class_300 = net.predict_by_sampling(test_X, num_samples=300).data.cpu().numpy().argmax(axis=1)\n",
        "#         print(\"sample 2 test error: {}\".format(100-compute_accu(pred_class_2, true_class, 2)))\n",
        "#         #print(\"sample 4 test error: {}\".format(100-compute_accu(pred_class_4, true_class, 2)))\n",
        "#         #print(\"sample 6 test error: {}\".format(100-compute_accu(pred_class_6, true_class, 2)))\n",
        "#         print(\"sample 20 test error: {}\".format(100-compute_accu(pred_class_20, true_class, 2)))\n",
        "#         #print(\"sample 100 test error: {}\".format(100-compute_accu(pred_class_100, true_class, 2)))\n",
        "#         #print(\"sample 300 test error: {}\".format(100-compute_accu(pred_class_300, true_class, 2)))\n",
        "#     else:\n",
        "#         raise ValueError\n",
        "\n",
        "#     test_accu = compute_accu(pred_class, true_class, 2)\n",
        "#     print('Epoch', i_ep, '|  Test Accuracy:', test_accu, '%', '| Test Error: ', round(100-test_accu, 2), '%')\n",
        "\n",
        "#     test_accu_lst.append(test_accu)\n",
        "\n",
        "# for p in net.parameters():\n",
        "#     print(p)\n",
        "\n",
        "# # to report the final test error, I will use the average of test errors of the last 10 epochs\n",
        "\n",
        "# report_test_accu_mean = np.average(test_accu_lst[-10:])\n",
        "# report_test_accu_std = np.std(test_accu_lst[-10:])\n",
        "# report_test_error_mean = round(100-report_test_accu_mean, 2)\n",
        "# print(\"Test Accuracy: {}\".format(report_test_accu_mean))\n",
        "# print(\"Test Error: {}\".format(report_test_error_mean))\n",
        "# print(\"Test Accuracy/Error Std: {}\".format(report_test_accu_std))\n",
        "\n",
        "# # save result to results folder: using pickle\n",
        "# result_folder_path = \"../../results/{}/\".format(experiment_name)\n",
        "# if not os.path.exists(result_folder_path):\n",
        "#     os.mkdir(result_folder_path)\n",
        "# with open(result_folder_path+\"train_accu_lst.pkl\", 'wb') as f:\n",
        "#     pickle.dump(train_accu_lst, f)\n",
        "# with open(result_folder_path+\"test_accu_lst.pkl\", 'wb') as f:\n",
        "#     pickle.dump(test_accu_lst, f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1353], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([0.1353], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([0.1353], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([0.1353], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([0.1353], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([0.1353], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "initial mu weights: [-0.08, 0.08]\n",
            "initial rho weights: [-2.5, -2.1]\n",
            "initial mu bias: [-0.08, 0.08]\n",
            "initial rho bias [-2.5, -2.1]\n",
            "BayesianNN(\n",
            "  Bayesian Layer, in_size:784, out_size:1200, activation_type:RELU\n",
            "  Bayesian Layer, in_size:1200, out_size:1200, activation_type:RELU\n",
            "  Bayesian Layer, in_size:1200, out_size:10, activation_type:SOFTMAX\n",
            "  \n",
            "  (layers): ModuleList(\n",
            "    (0): BayesianLayer(Bayesian Layer, in_size:784, out_size:1200, activation_type:RELU)\n",
            "    (1): BayesianLayer(Bayesian Layer, in_size:1200, out_size:1200, activation_type:RELU)\n",
            "    (2): BayesianLayer(Bayesian Layer, in_size:1200, out_size:10, activation_type:SOFTMAX)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FAR04_35rGFf",
        "colab_type": "code",
        "outputId": "2def91b8-3d88-4974-922c-1311a47ec228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2479
        }
      },
      "cell_type": "code",
      "source": [
        "arr = []\n",
        "for i in range (len(net.layers)):\n",
        "  weightdb = torch.log(torch.abs(net.layers[i].mu_weights)/torch.log(1 + torch.exp(net.layers[i].rho_weights))).view(-1).data.cpu().numpy()\n",
        "  print(net.layers[i].mu_weights)\n",
        "  arr.extend(weightdb)\n",
        "  biasdb = torch.log(torch.abs(net.layers[i].mu_bias)/torch.log(1 + torch.exp(net.layers[i].rho_bias))).view(-1).data.cpu().numpy()\n",
        "  arr.extend(biasdb)\n",
        "plt.hist(arr, bins = 10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0382,  0.0695,  0.0546,  ...,  0.0688,  0.0290, -0.0410],\n",
            "        [ 0.0506,  0.0627, -0.0570,  ...,  0.0293,  0.0680,  0.0185],\n",
            "        [-0.0197,  0.0723,  0.0480,  ...,  0.0450, -0.0469,  0.0101],\n",
            "        ...,\n",
            "        [-0.0146, -0.0084,  0.0673,  ..., -0.0018, -0.0066, -0.0044],\n",
            "        [-0.0401,  0.0228, -0.0616,  ..., -0.0232, -0.0179, -0.0365],\n",
            "        [-0.0394, -0.0112,  0.0357,  ...,  0.0514, -0.0435, -0.0078]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0756, -0.0089,  0.0447,  ..., -0.0629, -0.0095, -0.0608],\n",
            "        [-0.0787,  0.0759, -0.0556,  ...,  0.0220, -0.0170, -0.0073],\n",
            "        [ 0.0466, -0.0097,  0.0617,  ..., -0.0237,  0.0245, -0.0250],\n",
            "        ...,\n",
            "        [-0.0664, -0.0329, -0.0439,  ..., -0.0641,  0.0434, -0.0739],\n",
            "        [ 0.0213, -0.0717, -0.0270,  ..., -0.0626, -0.0057, -0.0184],\n",
            "        [ 0.0761,  0.0651, -0.0508,  ...,  0.0025, -0.0441, -0.0068]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0373,  0.0318,  0.0345,  ..., -0.0074,  0.0436,  0.0058],\n",
            "        [ 0.0744,  0.0418,  0.0690,  ...,  0.0383, -0.0736, -0.0292],\n",
            "        [ 0.0582,  0.0074, -0.0364,  ...,  0.0429,  0.0012,  0.0753],\n",
            "        ...,\n",
            "        [ 0.0362,  0.0778, -0.0732,  ..., -0.0053, -0.0084,  0.0440],\n",
            "        [ 0.0540, -0.0568,  0.0495,  ...,  0.0745,  0.0431, -0.0342],\n",
            "        [ 0.0044, -0.0701,  0.0271,  ...,  0.0565,  0.0343, -0.0513]],\n",
            "       device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1.,  0.,  0., ..., 62., 32., 14.]),\n",
              " array([-1.59837666e+01, -1.59821668e+01, -1.59805671e+01, ...,\n",
              "         1.01764759e-02,  1.17761902e-02,  1.33759044e-02]),\n",
              " <a list of 10000 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "stream",
          "text": [
            "Error in callback <function flush_figures at 0x7f2c1c5ee378> (for post_execute):\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mshow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2051\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2053\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2054\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2270\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   4394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4395\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbbox_artists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4396\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4397\u001b[0m             if (bbox is not None and\n\u001b[1;32m   4398\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mclip_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclip_box\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mclip_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclip_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mintersection\u001b[0;34m(bbox1, bbox2)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0my1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, points, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \"\"\"\n\u001b[1;32m    770\u001b[0m         \u001b[0mBboxBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             raise ValueError('Bbox points must be of the form '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2gHiEbnhhv8f",
        "colab_type": "code",
        "outputId": "bff16d4c-a2cc-4992-d0be-1188dd2da264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "cell_type": "code",
      "source": [
        "sgd_net = torch.load(\"SGD_weights.pt\")\n",
        "dropout_net = torch.load(\"dropout_weights.pt\")\n",
        "dropout_net.train()\n",
        "\n",
        "def expected_entropy(net, input_data, num_samples=100):\n",
        "    with torch.no_grad():\n",
        "        outputs = torch.empty(num_samples, input_data.size()[0], 10)\n",
        "        for i in range(num_samples):\n",
        "            outputs[i] = net.forward(input_data)\n",
        "            outputs[i] = torch.exp(outputs[i])+1e-45\n",
        "        outputs = outputs.mean(0)\n",
        "        MC = torch.sum(outputs*torch.log(outputs), dim = 1)\n",
        "    #MC = MC.mean(0)\n",
        "    return MC\n",
        "\n",
        "def test(net):\n",
        "    test_accu_lst = []\n",
        "    pred_class = net(test_X).data.cpu().numpy().argmax(axis=1)\n",
        "    true_class = test_Y.data.cpu().numpy().ravel()\n",
        "    test_accu = (pred_class == true_class).sum()\n",
        "    entropy = expected_entropy(net, test_X, 100)\n",
        "    entropy = entropy.data.cpu().numpy().ravel()\n",
        "    equ = pred_class == true_class\n",
        "    entropy_pair = sorted(list(zip(entropy, equ)), key=lambda tup: tup[0])\n",
        "    cur_test_size = test_size\n",
        "    for i in range(500):\n",
        "      cur_test_size-=1\n",
        "      if(entropy_pair[i][1]):\n",
        "        test_accu -= 1\n",
        "      test_accu_lst.append(test_accu/cur_test_size)\n",
        "    plt.plot(test_accu_lst, label='Train')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.xlabel('Data Removed')\n",
        "    plt.show()\n",
        "\n",
        "test(sgd_net)\n",
        "test(dropout_net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVDzdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzrlK8UTinHOuUv4fQ09tYshPQnAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "y-BS7wdXhhrG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "bayesian_parameters = list(net.parameters())\n",
        "bayesian_parameters = np.concatenate([bayesian_parameters[i].data.cpu().numpy().reshape(-1,) for i in range(len(bayesian_parameters)) if i % 2 == 0])\n",
        "\n",
        "sns.kdeplot(bayesian_parameters, shade=True, label=\"bayesian\")\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m_YWx4iHe146",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}